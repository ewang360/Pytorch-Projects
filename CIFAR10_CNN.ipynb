{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpMga_xhy2u4"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v0DBMbVHy2u4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Image Size: torch.Size([1, 32, 32])\n",
            "\n",
            "Training Set:   40000 samples\n",
            "Validation Set: 10000 samples\n",
            "Test Set:       10000 samples\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "\n",
        "# Change the images to grayscale\n",
        "# Convert to a tensor\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Download the base dataset files\n",
        "train_dataset = CIFAR10(\"~/data/CIFAR10\", train=True, download=True, transform=image_transforms) # 50000 training images\n",
        "test_dataset = CIFAR10(\"~/data/CIFAR10\", train=False, download=True, transform=image_transforms) # 10000 test images\n",
        "\n",
        "# Split the training dataset to separate a validation set\n",
        "train_dataset_percent = 0.8\n",
        "train_dataset_size = int(train_dataset_percent * len(train_dataset))\n",
        "validation_dataset_size = len(train_dataset) - train_dataset_size\n",
        "train_dataset, validation_dataset = torch.utils.data.random_split(train_dataset, [train_dataset_size, validation_dataset_size])\n",
        "\n",
        "# Get one image sample so that we can look at the shape\n",
        "image, label = train_dataset[0]\n",
        "\n",
        "print(\"Image Size: {}\".format(image.shape))\n",
        "print()\n",
        "print(\"Training Set:   {} samples\".format(len(train_dataset)))\n",
        "print(\"Validation Set: {} samples\".format(len(validation_dataset)))\n",
        "print(\"Test Set:       {} samples\".format(len(test_dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVT8-_GOy2u4"
      },
      "source": [
        "## Setup Training Variables\n",
        "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "08Hyl8zcy2u4"
      },
      "outputs": [],
      "source": [
        "num_epochs = 80\n",
        "batch_size = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycVoeaNH1YD4"
      },
      "source": [
        "## Create Dataloaders\n",
        "Dataloaders allow us to easily and efficiently load batches for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "I8KVAMNT1vDw"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "dataloaders = {\n",
        "    'train': train_loader,\n",
        "    'val': validation_loader,\n",
        "    'test': test_loader\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAF3YXCuy2u4"
      },
      "source": [
        "## Visualize Data\n",
        "\n",
        "View a sample from the dataset and dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FC6xYbUjy2u4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x13b719990>\n"
          ]
        }
      ],
      "source": [
        "import torchvision.utils\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "print(iter(dataloaders['train']))\n",
        "# images, labels = next(iter(dataloaders['train']))\n",
        "\n",
        "# fig = plt.figure(figsize=(16, 8))\n",
        "# out = torchvision.utils.make_grid(images, nrow=16)\n",
        "\n",
        "# plt.imshow(out.permute(1, 2, 0), cmap=\"gray\")\n",
        "\n",
        "# labels_map = {\n",
        "#     0: \"Airplane\",\n",
        "#     1: \"Automobile\",\n",
        "#     2: \"Bird\",\n",
        "#     3: \"Cat\",\n",
        "#     4: \"Deer\",\n",
        "#     5: \"Dog\",\n",
        "#     6: \"Frog\",\n",
        "#     7: \"Horse\",\n",
        "#     8: \"Ship\",\n",
        "#     9: \"Truck\",\n",
        "# }\n",
        "\n",
        "# figure = plt.figure(figsize=(8, 8))\n",
        "# cols, rows = 3, 3\n",
        "# for i in range(1, cols * rows + 1):\n",
        "#     sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
        "#     img, label = train_dataset[sample_idx]\n",
        "#     figure.add_subplot(rows, cols, i)\n",
        "#     plt.title(labels_map[label])\n",
        "#     plt.axis(\"off\")\n",
        "#     plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgL0qlzVy2u4"
      },
      "source": [
        "## Implement CNN\n",
        "\n",
        "### Input\n",
        "Accepts a 32x32xC image as input, where C is the number of color channels. If images are grayscale, C is 1.\n",
        "\n",
        "### Architecture\n",
        "**Layer 1: Convolutional.** The output shape should be 28x28x6.\n",
        "\n",
        "**Activation.** Your choice of activation function.\n",
        "\n",
        "**Pooling.** The output shape should be 14x14x6.\n",
        "\n",
        "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
        "\n",
        "**Activation.** Your choice of activation function.\n",
        "\n",
        "**Pooling.** The output shape should be 5x5x16.\n",
        "\n",
        "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `torch.flatten`.\n",
        "\n",
        "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
        "\n",
        "**Activation.** Your choice of activation function.\n",
        "\n",
        "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
        "\n",
        "**Activation.** Your choice of activation function.\n",
        "\n",
        "**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n",
        "\n",
        "### Output\n",
        "Return the result of the 2nd fully connected layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "sWnxvBF2y2u4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    # Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "\n",
        "    # Layer 2: Convolutional. Input = 14x14x6 Output = 10x10x16.\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "    # Layer 3: Fully Connected. Input = 400. Output = 120.\n",
        "    self.fc1 =  nn.Linear(400, 120)\n",
        "\n",
        "    # Layer 4: Fully Connected. Input = 120. Output = 84.\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "\n",
        "    # Layer 5: Fully Connected. Input = 84. Output = 10.\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Layer 1\n",
        "    x = self.conv1(x)\n",
        "    # Activation\n",
        "    x = F.relu(x)\n",
        "    # Pooling\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    # Layer 2\n",
        "    x = self.conv2(x)\n",
        "    # Activation\n",
        "    x = F.relu(x)\n",
        "    # Pooling\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    # Flatten\n",
        "    x = torch.flatten(x, 1)\n",
        "    # Layer 3\n",
        "    x = self.fc1(x)\n",
        "    # Activation\n",
        "    x = F.relu(x)\n",
        "    # Layer 4\n",
        "    x = self.fc2(x)\n",
        "    # Activation\n",
        "    x = F.relu(x)\n",
        "    # Layer 5\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4tFh7eIy2u4"
      },
      "source": [
        "## Training Setup\n",
        "This section defines the model and optimizer to use in training. The train_model function comes from the [PyTorch documentation](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NgcjGOFAy2u4"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "model = CNN()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "export_path = \"lenet.pt\"\n",
        "\n",
        "# Setup a device for training (use GPU if it's available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
        "  since = time.time()\n",
        "\n",
        "  val_acc_history = []\n",
        "\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        model.train()  # Set model to training mode\n",
        "      else:\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "\n",
        "      # Iterate over data.\n",
        "      for inputs, labels in dataloaders[phase]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        # track history if only in train\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          # Get model outputs and calculate loss\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "\n",
        "          # backward + optimize only if in training phase\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "      epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "      epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "      print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "      # deep copy the model\n",
        "      if phase == 'val' and epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "      if phase == 'val':\n",
        "        val_acc_history.append(epoch_acc)\n",
        "\n",
        "    print()\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "  print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "  # load best model weights\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model, val_acc_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2saDgQ3ry2u4"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "inAhA0plubM8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/79\n",
            "----------\n",
            "train Loss: 2.3021 Acc: 0.1123\n",
            "val Loss: 2.3008 Acc: 0.1288\n",
            "\n",
            "Epoch 1/79\n",
            "----------\n",
            "train Loss: 2.2977 Acc: 0.1320\n",
            "val Loss: 2.2935 Acc: 0.1257\n",
            "\n",
            "Epoch 2/79\n",
            "----------\n",
            "train Loss: 2.2695 Acc: 0.1606\n",
            "val Loss: 2.2188 Acc: 0.1720\n",
            "\n",
            "Epoch 3/79\n",
            "----------\n",
            "train Loss: 2.1819 Acc: 0.1900\n",
            "val Loss: 2.1612 Acc: 0.1826\n",
            "\n",
            "Epoch 4/79\n",
            "----------\n",
            "train Loss: 2.1232 Acc: 0.2268\n",
            "val Loss: 2.1249 Acc: 0.2091\n",
            "\n",
            "Epoch 5/79\n",
            "----------\n",
            "train Loss: 2.0595 Acc: 0.2567\n",
            "val Loss: 2.0701 Acc: 0.2497\n",
            "\n",
            "Epoch 6/79\n",
            "----------\n",
            "train Loss: 2.0008 Acc: 0.2811\n",
            "val Loss: 1.9987 Acc: 0.2759\n",
            "\n",
            "Epoch 7/79\n",
            "----------\n",
            "train Loss: 1.9267 Acc: 0.3086\n",
            "val Loss: 1.9078 Acc: 0.3174\n",
            "\n",
            "Epoch 8/79\n",
            "----------\n",
            "train Loss: 1.8619 Acc: 0.3347\n",
            "val Loss: 1.8767 Acc: 0.3262\n",
            "\n",
            "Epoch 9/79\n",
            "----------\n",
            "train Loss: 1.8012 Acc: 0.3579\n",
            "val Loss: 1.8606 Acc: 0.3301\n",
            "\n",
            "Epoch 10/79\n",
            "----------\n",
            "train Loss: 1.7577 Acc: 0.3690\n",
            "val Loss: 1.7707 Acc: 0.3596\n",
            "\n",
            "Epoch 11/79\n",
            "----------\n",
            "train Loss: 1.7103 Acc: 0.3901\n",
            "val Loss: 1.7056 Acc: 0.3859\n",
            "\n",
            "Epoch 12/79\n",
            "----------\n",
            "train Loss: 1.6736 Acc: 0.4061\n",
            "val Loss: 1.6906 Acc: 0.3979\n",
            "\n",
            "Epoch 13/79\n",
            "----------\n",
            "train Loss: 1.6352 Acc: 0.4200\n",
            "val Loss: 1.6617 Acc: 0.4089\n",
            "\n",
            "Epoch 14/79\n",
            "----------\n",
            "train Loss: 1.6031 Acc: 0.4303\n",
            "val Loss: 1.6129 Acc: 0.4224\n",
            "\n",
            "Epoch 15/79\n",
            "----------\n",
            "train Loss: 1.5694 Acc: 0.4435\n",
            "val Loss: 1.6073 Acc: 0.4282\n",
            "\n",
            "Epoch 16/79\n",
            "----------\n",
            "train Loss: 1.5406 Acc: 0.4552\n",
            "val Loss: 1.6454 Acc: 0.4097\n",
            "\n",
            "Epoch 17/79\n",
            "----------\n",
            "train Loss: 1.5151 Acc: 0.4622\n",
            "val Loss: 1.5406 Acc: 0.4519\n",
            "\n",
            "Epoch 18/79\n",
            "----------\n",
            "train Loss: 1.4852 Acc: 0.4742\n",
            "val Loss: 1.5548 Acc: 0.4462\n",
            "\n",
            "Epoch 19/79\n",
            "----------\n",
            "train Loss: 1.4739 Acc: 0.4789\n",
            "val Loss: 1.5471 Acc: 0.4568\n",
            "\n",
            "Epoch 20/79\n",
            "----------\n",
            "train Loss: 1.4520 Acc: 0.4858\n",
            "val Loss: 1.5053 Acc: 0.4643\n",
            "\n",
            "Epoch 21/79\n",
            "----------\n",
            "train Loss: 1.4228 Acc: 0.4984\n",
            "val Loss: 1.5081 Acc: 0.4637\n",
            "\n",
            "Epoch 22/79\n",
            "----------\n",
            "train Loss: 1.4182 Acc: 0.4991\n",
            "val Loss: 1.7027 Acc: 0.3953\n",
            "\n",
            "Epoch 23/79\n",
            "----------\n",
            "train Loss: 1.4126 Acc: 0.5024\n",
            "val Loss: 1.4726 Acc: 0.4790\n",
            "\n",
            "Epoch 24/79\n",
            "----------\n",
            "train Loss: 1.3756 Acc: 0.5151\n",
            "val Loss: 1.5106 Acc: 0.4717\n",
            "\n",
            "Epoch 25/79\n",
            "----------\n",
            "train Loss: 1.3574 Acc: 0.5209\n",
            "val Loss: 1.4523 Acc: 0.4865\n",
            "\n",
            "Epoch 26/79\n",
            "----------\n",
            "train Loss: 1.3413 Acc: 0.5276\n",
            "val Loss: 1.4865 Acc: 0.4747\n",
            "\n",
            "Epoch 27/79\n",
            "----------\n",
            "train Loss: 1.3235 Acc: 0.5350\n",
            "val Loss: 1.4803 Acc: 0.4771\n",
            "\n",
            "Epoch 28/79\n",
            "----------\n",
            "train Loss: 1.3100 Acc: 0.5398\n",
            "val Loss: 1.4764 Acc: 0.4855\n",
            "\n",
            "Epoch 29/79\n",
            "----------\n",
            "train Loss: 1.2938 Acc: 0.5458\n",
            "val Loss: 1.4570 Acc: 0.4896\n",
            "\n",
            "Epoch 30/79\n",
            "----------\n",
            "train Loss: 1.2757 Acc: 0.5514\n",
            "val Loss: 1.4214 Acc: 0.5031\n",
            "\n",
            "Epoch 31/79\n",
            "----------\n",
            "train Loss: 1.2527 Acc: 0.5602\n",
            "val Loss: 1.4307 Acc: 0.4987\n",
            "\n",
            "Epoch 32/79\n",
            "----------\n",
            "train Loss: 1.2354 Acc: 0.5682\n",
            "val Loss: 1.4655 Acc: 0.4902\n",
            "\n",
            "Epoch 33/79\n",
            "----------\n",
            "train Loss: 1.2384 Acc: 0.5678\n",
            "val Loss: 1.4149 Acc: 0.5108\n",
            "\n",
            "Epoch 34/79\n",
            "----------\n",
            "train Loss: 1.2117 Acc: 0.5748\n",
            "val Loss: 1.3992 Acc: 0.5176\n",
            "\n",
            "Epoch 35/79\n",
            "----------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/eileen/Documents/Projects/Pytorch-Projects/CIFAR10_CNN.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eileen/Documents/Projects/Pytorch-Projects/CIFAR10_CNN.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/eileen/Documents/Projects/Pytorch-Projects/CIFAR10_CNN.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model, _ \u001b[39m=\u001b[39m train_model(model, dataloaders, criterion, optimizer, num_epochs)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eileen/Documents/Projects/Pytorch-Projects/CIFAR10_CNN.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m torch\u001b[39m.\u001b[39msave(model, export_path)\n",
            "\u001b[1;32m/Users/eileen/Documents/Projects/Pytorch-Projects/CIFAR10_CNN.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eileen/Documents/Projects/Pytorch-Projects/CIFAR10_CNN.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m running_corrects \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eileen/Documents/Projects/Pytorch-Projects/CIFAR10_CNN.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Iterate over data.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/eileen/Documents/Projects/Pytorch-Projects/CIFAR10_CNN.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m dataloaders[phase]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eileen/Documents/Projects/Pytorch-Projects/CIFAR10_CNN.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m   inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eileen/Documents/Projects/Pytorch-Projects/CIFAR10_CNN.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m   labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1317\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1315\u001b[0m     \u001b[39m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1317\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown_workers()\n\u001b[1;32m   1318\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m \u001b[39m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \n\u001b[1;32m   1322\u001b[0m \u001b[39m# Check if the next sample has already been generated\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1442\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1438\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers:\n\u001b[1;32m   1439\u001b[0m     \u001b[39m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m     \u001b[39m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[39m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m     w\u001b[39m.\u001b[39mjoin(timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL)\n\u001b[1;32m   1443\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues:\n\u001b[1;32m   1444\u001b[0m     q\u001b[39m.\u001b[39mcancel_join_thread()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconnection\u001b[39;00m \u001b[39mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wait([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel], timeout):\n\u001b[1;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/connection.py:930\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    927\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    929\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 930\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39mselect(timeout)\n\u001b[1;32m    931\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    932\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selector\u001b[39m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = model.to(device)\n",
        "model, _ = train_model(model, dataloaders, criterion, optimizer, num_epochs)\n",
        "torch.save(model, export_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p8W0D7wg5z8"
      },
      "source": [
        "## Evaluation Function\n",
        "This function is deisgned to evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p4Vt21VAtzs"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader):\n",
        "  number_correct_predictions = 0\n",
        "  number_samples = 0\n",
        "  with torch.set_grad_enabled(False):\n",
        "    for images, labels in dataloader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      predicted_logits = model(images)\n",
        "      predicted_labels = torch.argmax(predicted_logits, dim=1)\n",
        "      correct_predictions = torch.sum(predicted_labels == labels)\n",
        "      number_correct_predictions += correct_predictions.item()\n",
        "      number_samples += len(images)\n",
        "  return float(number_correct_predictions) / number_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96fQpNFpy2u4"
      },
      "source": [
        "## Evaluate the Model\n",
        "Once you are completely satisfied with your model, evaluate the performance of the model on the test set.\n",
        "\n",
        "Be sure to only do this once!\n",
        "\n",
        "If you were to measure the performance of your trained model on the test set, then improve your model, and then measure the performance of your model on the test set again, that would invalidate your test results. You wouldn't get a true measure of how well your model would perform against real data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8F-Qr5Fy2u4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy = 0.539\n"
          ]
        }
      ],
      "source": [
        "# Load the best model\n",
        "model = torch.load(\"lenet.pt\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "test_accuracy = evaluate(model, dataloaders['test'])\n",
        "print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "LeNet-Lab-Solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "metadata": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
